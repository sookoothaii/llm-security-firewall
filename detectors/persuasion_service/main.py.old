"""
Persuasion & Misinformation Detector Service - LLM Firewall Battle Plan
=======================================================================

Detects persuasive rhetoric and misinformation patterns.
FastAPI microservice for Outer Ring detection.

Creator: HAK_GAL (Joerg Bollwahn)
Date: 2025-12-07
Status: Phase 2 - Microservices
License: MIT
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, List, Optional, Any
import logging
import re
import time
import sys
from pathlib import Path

# Add project root to path for pattern library
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

try:
    from prometheus_client import Counter, Histogram, generate_latest
    HAS_PROMETHEUS = True
except ImportError:
    HAS_PROMETHEUS = False
    logging.warning("prometheus_client not installed. Metrics disabled.")

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Prometheus metrics (if available)
if HAS_PROMETHEUS:
    REQUEST_COUNTER = Counter(
        'persuasion_requests_total',
        'Total requests to persuasion/misinfo detector',
        ['status']
    )
    
    LATENCY_HISTOGRAM = Histogram(
        'persuasion_request_duration_seconds',
        'Request duration in seconds',
        buckets=[0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0]
    )
else:
    REQUEST_COUNTER = None
    LATENCY_HISTOGRAM = None

app = FastAPI(
    title="Persuasion & Misinformation Detector Service",
    description="Detects persuasive rhetoric and misinformation patterns",
    version="1.0.0"
)


class DetectorRequest(BaseModel):
    """Request format matching detector registry."""
    text: str
    context: Optional[Dict[str, Any]] = None
    risk_score: Optional[float] = None
    categories: Optional[List[str]] = None
    tools: Optional[List[str]] = None


class DetectorResponse(BaseModel):
    """Response format matching detector registry."""
    detector_name: str = "persuasion_misinfo"
    risk_score: float
    category: Optional[str] = None
    confidence: float = 0.0
    matched_patterns: List[str] = []
    metadata: Dict[str, Any] = {}
    error: Optional[str] = None
    latency_ms: float = 0.0


def analyze_persuasion_patterns(text: str) -> tuple[Dict[str, float], List[str]]:
    """Rule-based persuasion/misinfo detection with advanced patterns."""
    # Try to use advanced pattern library if available
    try:
        from llm_firewall.patterns.advanced_patterns import get_pattern_library
        pattern_lib = get_pattern_library()
        advanced_matches = pattern_lib.check_text(text)
        
        # Separate by category
        misinfo_matches = [m for m in advanced_matches if m["category"] == "misinformation"]
        persuasion_matches = [m for m in advanced_matches if m["category"] == "persuasion"]
        financial_matches = [m for m in advanced_matches if m["category"] == "financial_scam"]
        
        misinfo_score = 0.0
        persuasion_score = 0.0
        matched_patterns = []
        
        # Calculate scores from advanced patterns
        if misinfo_matches:
            max_severity = max(m["severity"] for m in misinfo_matches)
            misinfo_score = min(1.0, max_severity / 10.0)
            matched_patterns.extend([m["name"] for m in misinfo_matches])
        
        if persuasion_matches:
            max_severity = max(m["severity"] for m in persuasion_matches)
            persuasion_score = min(1.0, max_severity / 10.0)
            matched_patterns.extend([m["name"] for m in persuasion_matches])
        
        if financial_matches:
            max_severity = max(m["severity"] for m in financial_matches)
            persuasion_score = max(persuasion_score, min(1.0, max_severity / 10.0))
            matched_patterns.extend([m["name"] for m in financial_matches])
        
        if matched_patterns:
            return {
                "misinformation": misinfo_score,
                "persuasion": persuasion_score
            }, matched_patterns
    except ImportError:
        pass  # Fall back to basic patterns
    
    # Basic patterns (fallback)
    persuasion_patterns = [
        # Emotional manipulation
        (r"\b(urgent|immediate|limited time|act now|don't miss)\b", 0.3, "urgency_manipulation"),
        (r"\b(exclusive|secret|they don't want you to know|hidden truth)\b", 0.4, "exclusivity_claim"),
        (r"\b(guaranteed|100%|proven|miracle|breakthrough)\b", 0.3, "unrealistic_claims"),
        
        # Misinformation patterns
        (r"\b(fake news|hoax|conspiracy|cover[ -]?up)\b", 0.5, "misinformation_claim"),
        (r"\b(doctors hate this|big (pharma|tech) is hiding)\b", 0.6, "authority_undermining"),
        (r"\b(natural cure|alternative medicine|ignore your doctor)\b", 0.5, "medical_misinformation"),
        (r"\b(die medien verschweigen|offizielle narrative)\b", 0.6, "media_distrust_german"),
        (r"\b(sie wollen nicht, dass du weiÃŸt)\b", 0.5, "conspiracy_german"),
        
        # Financial scams
        (r"\b(get rich quick|make money fast|easy money)\b", 0.5, "financial_scam"),
        (r"\b(risk-free|no investment|work from home)\b", 0.4, "too_good_to_be_true"),
        (r"\b(act now|limited time|make millions)\b", 0.5, "financial_urgency"),
        
        # Political manipulation
        (r"\b(wake up sheeple|deep state|globalists)\b", 0.5, "conspiracy_theory"),
        (r"\b(us vs them|elites vs ordinary people)\b", 0.4, "divisive_rhetoric"),
        
        # Trust undermining
        (r"\b(mainstream media|establishment|system)\b.*\b(lie|deceive|hide)\b", 0.5, "trust_undermining"),
        (r"\b(official sources|government|experts).*\b(wrong|lying|cover-up)\b", 0.6, "authority_rejection"),
    ]
    
    misinfo_score = 0.0
    persuasion_score = 0.0
    matched_patterns = []
    
    text_lower = text.lower()
    
    for pattern, weight, pattern_name in persuasion_patterns:
        matches = re.findall(pattern, text_lower, re.IGNORECASE)
        if matches:
            # Categorize pattern
            if any(keyword in pattern_name for keyword in ["misinformation", "conspiracy", "hoax", "fake"]):
                misinfo_score = min(1.0, misinfo_score + weight)
            else:
                persuasion_score = min(1.0, persuasion_score + weight)
            
            matched_patterns.append(pattern_name)
    
    # Boost for multiple patterns
    if len(matched_patterns) > 1:
        boost = min(0.2, (len(matched_patterns) - 1) * 0.05)
        misinfo_score = min(1.0, misinfo_score + boost)
        persuasion_score = min(1.0, persuasion_score + boost)
    
    # Combined score (use maximum)
    combined_score = max(misinfo_score, persuasion_score)
    
    return {
        "misinformation": misinfo_score,
        "persuasion": persuasion_score,
        "combined": combined_score,
        "benign": 1.0 - combined_score
    }, matched_patterns


@app.post("/v1/detect", response_model=DetectorResponse)
async def detect(request: DetectorRequest):
    """
    Detect persuasion and misinformation.
    
    Endpoint matches detector registry format.
    """
    start_time = time.time()
    
    if REQUEST_COUNTER:
        REQUEST_COUNTER.labels(status='received').inc()
    
    try:
        text = request.text
        context = request.context or {}
        
        # Analyze text
        scores, matched_patterns = analyze_persuasion_patterns(text)
        
        # Context adjustment
        topic = context.get("topic", "").lower()
        if topic in ["health", "finance", "politics"]:
            # Increase sensitivity for sensitive topics
            scores["misinformation"] = min(1.0, scores["misinformation"] * 1.3)
            scores["persuasion"] = min(1.0, scores["persuasion"] * 1.2)
            scores["combined"] = max(scores["misinformation"], scores["persuasion"])
        
        # Use combined score as risk_score
        risk_score = scores["combined"]
        
        # Determine category
        if scores["misinformation"] > scores["persuasion"]:
            category = "misinformation"
            confidence = scores["misinformation"]
        elif scores["persuasion"] > 0.0:
            category = "persuasion"
            confidence = scores["persuasion"]
        else:
            category = None
            confidence = 0.0
        
        latency_ms = (time.time() - start_time) * 1000
        
        if REQUEST_COUNTER:
            REQUEST_COUNTER.labels(status='success').inc()
        if LATENCY_HISTOGRAM:
            LATENCY_HISTOGRAM.observe(latency_ms / 1000.0)
        
        return DetectorResponse(
            risk_score=risk_score,
            category=category,
            confidence=confidence,
            matched_patterns=matched_patterns,
            metadata={
                "method": "rule_based",
                "scores": scores,
                "context": context
            },
            latency_ms=latency_ms
        )
        
    except Exception as e:
        logger.error(f"Classification error: {e}", exc_info=True)
        
        if REQUEST_COUNTER:
            REQUEST_COUNTER.labels(status='error').inc()
        
        # Fail-open: Return low risk on error
        return DetectorResponse(
            risk_score=0.0,
            category=None,
            confidence=0.0,
            matched_patterns=[],
            metadata={},
            error=str(e),
            latency_ms=(time.time() - start_time) * 1000
        )


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "service": "persuasion_misinfo",
        "version": "1.0.0"
    }


@app.get("/metrics")
async def metrics():
    """Prometheus metrics endpoint."""
    if HAS_PROMETHEUS:
        return generate_latest()
    else:
        return {"error": "Prometheus client not available"}


@app.get("/info")
async def service_info():
    """Service information."""
    return {
        "name": "persuasion_misinfo_detector",
        "version": "1.0.0",
        "description": "Detects persuasive rhetoric and misinformation patterns",
        "categories": ["misinformation", "persuasion", "manipulation"],
        "endpoints": {
            "detect": "POST /v1/detect",
            "health": "GET /health",
            "metrics": "GET /metrics"
        }
    }
