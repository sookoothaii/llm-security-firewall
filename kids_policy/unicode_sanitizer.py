#!/usr/bin/env python3
"""
UnicodeSanitizer - HYDRA-14.5 Extension + v2.0 Emoji Demojizer
==============================================================
Sanitizes Unicode text: removes Zero-Width, replaces Homoglyphs, decomposes Umlauts
v2.0: Adds Emoji Demojization (NEMESIS-04 Fix)

Author: HAK_GAL (Joerg Bollwahn)
Date: 2025-11-28
Status: HYDRA-14.5 Implementation + v2.0 Emoji Support
"""

import re
import unicodedata
import logging
from typing import Tuple, Dict

# Try to import emoji library (optional dependency)
try:
    import emoji

    HAS_EMOJI_LIB = True
except ImportError:
    HAS_EMOJI_LIB = False
    emoji = None  # type: ignore[assignment]

logger = logging.getLogger(__name__)


class UnicodeSanitizer:
    """
    Unicode sanitization for HYDRA-14.5.

    Handles:
    - Zero-Width characters (removal)
    - Homoglyphs (Cyrillic, Greek â†’ Latin)
    - Umlaut decomposition (Ã¶ â†’ o, Ã¤ â†’ a, Ã¼ â†’ u, ÃŸ â†’ ss)
    """

    # Zero-Width characters
    INVISIBLE_CHARS = [
        "\u200b",  # ZWSP
        "\u200c",  # ZWNJ
        "\u200d",  # ZWJ
        "\u2060",  # WJ
        "\u180e",  # Mongolian Vowel Separator
        "\ufeff",  # BOM
    ]

    # Cyrillic homoglyphs (common ones used for evasion)
    CYRILLIC_HOMOGLYPH_MAP = {
        # Cyrillic lowercase
        "\u0430": "a",  # Ð° (Cyrillic a)
        "\u0435": "e",  # Ðµ (Cyrillic e)
        "\u043e": "o",  # Ð¾ (Cyrillic o)
        "\u0440": "p",  # Ñ€ (Cyrillic p)
        "\u0441": "c",  # Ñ (Cyrillic c)
        "\u0443": "y",  # Ñƒ (Cyrillic y)
        "\u0445": "x",  # Ñ… (Cyrillic x)
        "\u044a": "b",  # ÑŠ (hard sign, sometimes used as b)
        "\u0438": "i",  # Ð¸ (Cyrillic i)
        "\u043c": "m",  # Ð¼ (Cyrillic m)
        "\u043d": "h",  # Ð½ (Cyrillic n)
        "\u0442": "t",  # Ñ‚ (Cyrillic t)
        # Cyrillic uppercase
        "\u0410": "A",  # Ð
        "\u0415": "E",  # Ð•
        "\u041e": "O",  # Ðž
        "\u0420": "P",  # Ð 
        "\u0421": "C",  # Ð¡
        "\u0423": "Y",  # Ð£
        "\u0425": "X",  # Ð¥
        "\u0418": "I",  # Ð˜
        "\u041c": "M",  # Ðœ
        "\u041d": "H",  # Ð
        "\u0422": "T",  # Ð¢
        "\u041c": "M",  # Ðœ (Cyrillic M)
    }

    # Greek homoglyphs (less common but still used)
    GREEK_HOMOGLYPH_MAP = {
        "\u03b1": "a",  # Î±
        "\u0391": "A",  # Î‘
        "\u03c4": "t",  # Ï„
        "\u03a4": "T",  # Î¤
        "\u03bf": "o",  # Î¿
        "\u039f": "O",  # ÎŸ
        "\u03c1": "p",  # Ï
        "\u03bd": "v",  # Î½
        "\u0392": "B",  # Î’
        "\u0395": "E",  # Î•
    }

    def __init__(self, enable_emoji_demojize: bool = True):
        """
        Initialize UnicodeSanitizer.

        Args:
            enable_emoji_demojize: Enable emoji demojization (v2.0 feature)
        """
        # Combine all homoglyph maps
        self.HOMOGLYPH_MAP = {**self.CYRILLIC_HOMOGLYPH_MAP, **self.GREEK_HOMOGLYPH_MAP}

        # v2.0: Emoji demojization
        self.enable_emoji_demojize = enable_emoji_demojize and HAS_EMOJI_LIB

        if self.enable_emoji_demojize:
            logger.info("UnicodeSanitizer: Emoji demojization enabled (v2.0)")
        elif enable_emoji_demojize and not HAS_EMOJI_LIB:
            logger.warning(
                "UnicodeSanitizer: Emoji demojization requested but 'emoji' library not installed. "
                "Install with: pip install emoji"
            )

    def decompose_umlaut(self, text: str) -> str:
        """
        Decompose German umlauts to ASCII equivalents.

        Ã¶ â†’ o, Ã¤ â†’ a, Ã¼ â†’ u, ÃŸ â†’ ss
        """
        # Normalize to NFD first (separates base + combining marks)
        text = unicodedata.normalize("NFD", text)

        # Replace umlauts
        text = text.replace("Ã¶", "o").replace("Ã¤", "a").replace("Ã¼", "u")
        text = text.replace("Ã–", "O").replace("Ã„", "A").replace("Ãœ", "U")
        text = text.replace("ÃŸ", "ss")

        # Remove combining marks (diacritics) that might remain
        text = "".join(
            char
            for char in text
            if unicodedata.category(char) != "Mn"  # Mark, nonspacing
        )

        return text

    def demojize_text(self, text: str) -> str:
        """
        Convert emojis to their textual representation (v2.0 - NEMESIS-04 Fix).

        Uses aggressive threat mapping to prevent harmless translations.
        Example: ðŸ”« -> "firearm pistol weapon" (not "water pistol")

        Args:
            text: Input text with emojis

        Returns:
            Text with emojis replaced by descriptive words (aggressive threat mapping)
        """
        if not self.enable_emoji_demojize:
            return text

        try:
            # STEP 1: Standard demojize (converts to :emoji_name: format)
            # Use 'alias' language for standard shortcodes
            demojized = emoji.demojize(text, language="alias")

            # STEP 2: THREAT MAP OVERRIDE (Aggressive Translation)
            # The standard emoji library translates ðŸ”« as ":water_pistol:" which sounds harmless.
            # We force the semantic meaning of a weapon here.
            threat_map = {
                ":water_pistol:": " firearm pistol weapon ",  # ðŸ”« (Critical fix)
                ":bomb:": " explosive device bomb ",  # ðŸ’£
                ":kitchen_knife:": " lethal knife weapon ",  # ðŸ”ª
                ":dagger:": " lethal weapon stab ",  # ðŸ—¡ï¸
                ":drop_of_blood:": " blood gore injury ",  # ðŸ©¸
                ":pill:": " drugs narcotics medication ",  # ðŸ’Š
                ":syringe:": " heroin injection drugs ",  # ðŸ’‰
                ":collision:": " explosion blast damage ",  # ðŸ’¥
                ":skull_and_crossbones:": " death poison hazard ",  # â˜ ï¸
                ":exploding_head:": " explosion blast damage ",  # ðŸ¤¯
                ":school:": " school building education ",  # ðŸ«
            }

            # Replace soft tags with hard keywords BEFORE removing colons
            for soft_tag, hard_keywords in threat_map.items():
                if soft_tag in demojized:
                    demojized = demojized.replace(soft_tag, hard_keywords)
                    logger.debug(
                        f"[UnicodeSanitizer v2.0] Threat map override: {soft_tag} -> {hard_keywords.strip()}"
                    )

            # STEP 3: Semantic cleaning
            # Remove remaining colons and underscores from harmless emojis
            # (e.g., :smile: -> smile)
            cleaned = demojized.replace(":", " ").replace("_", " ")

            # Clean up multiple spaces
            cleaned = " ".join(cleaned.split())

            return cleaned
        except Exception as e:
            logger.warning(f"Emoji demojization failed: {e}. Using original text.")
            return text

    def sanitize(self, text: str) -> Tuple[str, Dict[str, bool]]:
        """
        Sanitize text: remove Zero-Width, replace Homoglyphs, decompose Umlauts.
        v2.0: Also demojize emojis to text (NEMESIS-04 Fix).

        Returns:
            Tuple of (sanitized_text, flags_dict)
            flags_dict contains: has_zero_width, has_homoglyph, has_umlaut, has_emoji
        """
        flags = {
            "has_zero_width": False,
            "has_homoglyph": False,
            "has_umlaut": False,
            "has_emoji": False,
        }

        original_text = text

        # v2.0: Step 0 - Demojize emojis FIRST (before other processing)
        # This ensures emojis are converted to text that Semantic Guard can understand
        if self.enable_emoji_demojize:
            # Check if text contains emojis
            if emoji.emoji_count(text) > 0:
                flags["has_emoji"] = True
                text = self.demojize_text(text)
                logger.debug(
                    f"[UnicodeSanitizer v2.0] Demojized emojis: {original_text[:50]}... -> {text[:50]}..."
                )

        # 1. Check and remove Zero-Width characters
        for char in self.INVISIBLE_CHARS:
            if char in text:
                flags["has_zero_width"] = True
                text = text.replace(char, "")

        # 2. Check and replace Homoglyphs
        for homoglyph, latin in self.HOMOGLYPH_MAP.items():
            if homoglyph in text:
                flags["has_homoglyph"] = True
                text = text.replace(homoglyph, latin)

        # 3. Check for umlauts (before decomposition)
        umlaut_chars = ["Ã¤", "Ã¶", "Ã¼", "Ã„", "Ã–", "Ãœ", "ÃŸ"]
        if any(umlaut in original_text for umlaut in umlaut_chars):
            flags["has_umlaut"] = True

        # 4. Decompose umlauts
        text = self.decompose_umlaut(text)

        return text, flags

    def contains_suspicious_unicode(self, text: str) -> bool:
        """
        Quick check if text contains suspicious Unicode.

        Returns True if Zero-Width, Homoglyphs, or suspicious scripts detected.
        """
        sanitized, flags = self.sanitize(text)
        return flags["has_zero_width"] or flags["has_homoglyph"]

    def detect_cyrillic_in_text(self, text: str) -> bool:
        """Check if text contains Cyrillic characters."""
        return bool(re.search(r"[\u0400-\u04FF]", text))

    def detect_greek_in_text(self, text: str) -> bool:
        """Check if text contains Greek characters."""
        return bool(re.search(r"[\u0370-\u03FF]", text))
